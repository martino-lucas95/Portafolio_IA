{% extends 'portfolio/base.html' %}
{% load static %}

{% block title %}Clustering{% endblock %}

{% block content %}
<div class="container">
    <h1 class="text-center mb-4">Subtipos de Clustering</h1>
    
    <div class="row">
        <div class="col-md-6">
            <div class="card">
                <div class="card-body">
                    <h5 class="card-title">K-Means Clustering</h5>
                    <p class="card-text">
                        K-Means es un algoritmo de clustering que particiona los datos en "K" grupos, donde cada punto pertenece al grupo con el centroide más cercano.
                    </p>
                    <h6>¿Cuándo usarlo?</h6>
                    <p>Es útil cuando tienes una cantidad conocida de clusters o grupos y los datos tienen límites bien definidos. Se usa en segmentación de clientes, agrupación de documentos, entre otros.</p>
                    <h6>¿Qué necesita?</h6>
                    <p>Es importante que los datos estén normalizados, ya que K-Means se basa en la distancia euclidiana. Además, el número de clusters debe ser conocido o estimado mediante el codo de K o el método de silueta.</p>
                </div>
            </div>
        </div>

        <div class="col-md-6">
            <div class="card">
                <div class="card-body">
                    <h5 class="card-title">DBSCAN (Density-Based Spatial Clustering)</h5>
                    <p class="card-text">
                        DBSCAN es un algoritmo que encuentra clusters basándose en la densidad de los puntos, identificando grupos como regiones densas separadas por regiones menos densas.
                    </p>
                    <h6>¿Cuándo usarlo?</h6>
                    <p>Es ideal para datasets con forma arbitraria y donde no se conoce el número de clusters. Funciona bien en detección de anomalías y clustering de datos espaciales.</p>
                    <h6>¿Qué necesita?</h6>
                    <p>No requiere datos normalizados, pero es sensible a los parámetros de distancia (`eps`) y el número mínimo de puntos en un cluster (`minPts`). Ajustar estos parámetros es clave.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="row mt-4">
        <div class="col-md-6">
            <div class="card">
                <div class="card-body">
                    <h5 class="card-title">Hierarchical Clustering</h5>
                    <p class="card-text">
                        El clustering jerárquico construye un árbol de clusters, donde cada nivel del árbol representa una fusión o división de clusters. Se pueden obtener clusters a diferentes niveles de granularidad.
                    </p>
                    <h6>¿Cuándo usarlo?</h6>
                    <p>Es útil cuando no se sabe el número de clusters de antemano o cuando se quiere visualizar la estructura jerárquica de los datos, como en el análisis de taxonomías.</p>
                    <h6>¿Qué necesita?</h6>
                    <p>No requiere normalización, pero es sensible a la métrica de distancia utilizada. Funciona mejor con datasets pequeños a medianos debido a su complejidad computacional.</p>
                </div>
            </div>
        </div>

        <div class="col-md-6">
            <div class="card">
                <div class="card-body">
                    <h5 class="card-title">Mean Shift Clustering</h5>
                    <p class="card-text">
                        Mean Shift es un algoritmo no paramétrico que agrupa los datos basándose en la densidad del gradiente. No requiere definir un número de clusters por adelantado.
                    </p>
                    <h6>¿Cuándo usarlo?</h6>
                    <p>Se usa cuando no se sabe el número de clusters de antemano y se buscan clusters de forma arbitraria. Ejemplos incluyen seguimiento de objetos y segmentación de imágenes.</p>
                    <h6>¿Qué necesita?</h6>
                    <p>Es importante ajustar el parámetro de ancho de banda (`bandwidth`) correctamente. No requiere datos normalizados, pero es computacionalmente costoso.</p>
                </div>
            </div>
        </div>
    </div>

    <div class="description mt-5">
        <h3>¿Cuándo aplicar Clustering?</h3>
        <p>
            El clustering se aplica cuando se desea agrupar puntos de datos en función de características similares, sin tener etiquetas predefinidas. Es útil en análisis exploratorio de datos y en situaciones donde se desconoce la estructura subyacente.
        </p>
        <h4>¿Qué precondiciones se deben cumplir?</h4>
        <ul>
            <li><strong>Normalización/Estandarización:</strong> Para algoritmos basados en distancia como K-Means, es crucial normalizar los datos para que las características en diferentes escalas no distorsionen los resultados.</li>
            <li><strong>Parámetros adecuados:</strong> Algoritmos como DBSCAN y Mean Shift requieren ajustes en parámetros clave (como `eps` o `bandwidth`) para obtener buenos resultados.</li>
            <li><strong>Balanceo de clusters:</strong> En algunos casos, es importante asegurarse de que los clusters sean de tamaño equilibrado, aunque no siempre es necesario.</li>
        </ul>
    </div>
</div>
{% endblock %}
